---
layout: post
title: "Zookeeper的应用场景"
date: 2017-05-03
description: "Zookeeper的应用场景"
tag: zookeeper
---   


## 概述
    Zookeeper是一个典型的发布、订阅模式的分布式数据管理与协调框架。
    通过对Zookeeper中丰富的数据节点类型进行交叉使用、配合Watcher事件通知机制，可以非常方便的构建一系列分布式应用中涉及到的核心功能，如数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、Master选举、分布式锁和分布式队列。
    Zookeeper是一个高可用的分布式数据管理与协调框架。基于对ZAB算法的实现，该框架能够很好地保证分布式环境中数据的一致性。

### 一.数据发布/订阅
        数据发布/订阅(Publish/Subscribe)系统，即所谓的配置中心，就是发布者将数据发布到Zookeeper的一个或一系列节点上，供订阅者进行数据订阅，进而达到动态获取数据的目的，实现配置信息的集中式管理和数据的动态更新。
        发布/订阅系列一般有俩种设计模式，分别是推(push)模式和拉(pull)模式。在推的模式中，服务端主动将数据更新发送给所有订阅者的客户端；而拉模式则是由客户端主动发起请求来获取最新数据，通常客户端都是采用定时进行轮询拉取的方式。而Zookeeper采用的是推拉结合的方式：客户端向服务器端注册自己需要关注的节点，一旦该节点的数据发生变更，那么服务端就会向相应的客户端发送watcher事件通知，客户端接收到这个消息通知之后，需要主动到服务端获取最新的数据。
        在实际应用系统开发中，经常会碰到这样的需求：系统中需要使用一些通用的配置信息，例如机器列表信息、运行时的开关配置、数据库配置信息等。这些全局配置配置信息具备以下3个特性：
         1.数据量通常比较小
         2.数据内容在运行时会发生动态变化    
         3.集群中各机器共享，配置一致
        这类配置信息，一般的做法通常可以选择将其存储在本地配置文件或是内存变量中(这种类型的配置在集群规模不大，配置变更不频繁的情况下都能解决配置管理的问题).
        例子:数据库切换”的应用场景，如何使用ZK来实现配置管理？
            1.配置存储
            在进行配置管理之前，首先我们需要将初始化配置存储到ZK上去。一般情况，在ZK上选取一个数据节点用于配置的存储。如：/configserver/app1/database_config.将集中管理的配置信息写入到该数据节点中去，例如：
            #DBCP
            dbcp.driverClassName=com.mysql.jdbc.Driver
            dbcp.JDBCUrl = jdbc:mysql://1.1.1.1:3306/allenkeeper
            dbcp.characterEncoding=GBK
            dbcp.username = allen
            dbcp.password = 123
            dbcp.maxActive = 30
            dbcp.maxIdle = 10
            dbcp.maxWait = 10000
            2.配置获取
            集群中每台机器在启动初始化阶段，首先会从上面提到的ZK配置节点上读取数据库信息，同时，客户端还需要在该配置节点上注册一个数据变更的Watcher监听，一旦发生节点数据变更，所有订阅的客户端都能够获取到数据变更通知。
            3.配置变更
            在系统运行过程中，可能会出现需要进行数据库切换的情况，这个时候就需要进行配置变更。借助ZK，只需要对ZK上配置节点的内容进行更新，ZK就能帮助我么将数据变更的通知发送到各个客户端，每个客户端在接收到这个变更通知后，就可以重新进行最新数据的获取。
        
### 二.负载均衡
        什么是负载均衡：用来对多个计算机、网络连接、CPU、磁盘驱动器或其他资源进行分配负载，以达到优化资源使用、最大化吞吐率、最小化响应时间和避免过载的目的。通常负载均衡可以分为硬件和软件负载均衡俩类，本节主要探讨的是ZK在软负载均衡中的应用场景。
        在分布式系统中，负载均衡更是一种普遍的技术，基本上每一个分布式系统都需要使用负载均衡。分布式系统具有对等性，为了保证系统的高可用性，通常采用副本的方式来对数据和服务进行部署
        ZK实现动态DNS方案：
        域名配置
            和配置管理一样，首先创建一个节点来进行域名配置；/DDNS/app1/server.app1.company1.com.
            IP地址和端口配置：
              单个IP：PORT
              192.168.0.1:8080
              多个IP:PORT
              192.168.0.1:8080，192.168.0.2:8080
        域名解析     
            DDNS中，域名的解析过程都是由每个应用自己负责的。通常应用都会首先从域名节点中获取一份IP地址和端口的配置，进行自行解析。同时，每个应用还会在域名节点上注册一个数据变更Watcher监听，以便及时收到域名变更的通知
       自动化的DNS服务
       
### 三、分布式协调/通知
        分布式协调/通知服务是分布式系统中不可缺少的，是将不同的分布式组件有机结合起来的关键。对于一个在多台机器上部署运行的应用而言，通常需要一个协调者(Coordinator)来控制整个系统的运行流畅，例如分布式的事务的处理、机器间的互相协调等。同时，引入这样一个协调，便于将分布式协调的职责从应用中分离出来，从而可以大大减少系统之间的耦合性，而且能够显著提高系统的可扩展性。
        
        ZooKeeper中特有的Watcher注册与异步通知机制，能够很好地实现分布式环境下不同机器，甚至是不同系统之间的协调与通知，从而实现对数据变更的实时处理。基于ZooKeeper实现分布式协调与通知功能，通常的做法是 不同的客户端都对ZooKeeper上同一个数据节点进行Watcher注册，监听数据节点的变化。
       
        MySQL数据复制总线：MySql_Replicator
       
        MySQL数据复制总线是一个实时数据复制框架，用于在不同的MySQL数据库实例之间进行异步复制和数据变化通知。整个系统是一个由MySQL数据库集群、消息队列系统、任务管理监控平台以及ZooKeeper集群等组件共同构成的一个包含数据生产者，复制管理和数据消费者等部分的数据总线。
        在该系统中，ZooKeeper主要负责进行一系列的分布式协调工作，在具体的实现上，根据功能将数据复制组件划分为三个核心子模块：Core，Server和Monitor，每个模块分别为一个单独的进程，通过ZooKeeper进行数据交换。
        Core ： 实现了数据复制的核心逻辑，其将数据复制封装成管道，并抽象出生产者和消费者俩个概念，其中生产者通常是MySQL数据库的BinLog日志
        Server：负责启动和停止复制任务
        Monitor：负责监控任务的运行状态，如果在数据复制期间发生异常或出现故障会进行告警

### 四、一种通用的分布式系统机器间通信方式
        在绝大部分的分布式系统中，系统机器间的通信无外乎心跳检测，工作进度汇报和系统调度这三种类型。
    1.心跳检测
        机器间的心跳检测机制是指在分布式环境中，不同机器之间需要检测到彼此是否正常运行。基于ZooKeeper的临时节点的特性，可以让不同的机器都在ZooKeeper的一个指定节点下创建临时子节点 ，不同的机器之间可以根据这个特性来判断客户端机器是否存活。通过这种方式检测系统和被检测系统之间并不需要直接相关联，而是通过ZK上的某个节点进行管理，大大减少了系统的耦合
        
    2.工作进度汇报
        在一个常见的任务分发系统中， 通常任务被分发到不停的机器上去执行后，需要实时地将自己的任务进行进度汇报给分发系统。这时可以通过ZK来实现。在ZK上选择一个节点，每个任务客户端都在这个节点下面创建临时子节点，这样便可以实现俩个功能：
            1.通过判断临时节点是否存在来确定任务极其是否存活
            2.各个任务机器会实时地将自己任务执行进度写到这个临时节点上去，以便中心系统能够实时地获取到任务的执行进度
            3.系统调度
        使用ZK，能够实现另外一种系统调度模式：一个分布式系统由控制台和一些客户端系统俩部分组成，控制台的职责就是需要将一些指令信息发送给所有的客户端，以便控制它们进行相应的业务逻辑。

### 五、集群管理
        所谓的集群管理，包括集群监控与集群控制俩大块，前者侧重对集群运行时状态的收集，后者则是对集群进行操作与控制。在日常开发和运维过程汇总，我们经常会有类似于如下的操作：
         1.当前集群中究竟有多少台机器在工作
         2.对集群中每台机器的运行时状态进行数据收集
         3.对集群中机器进行上下线操作
        ZOOKeeper具有以下两大特性：
             1.客户端如果对ZOOKeeper的一个数据节点注册Watcher监听，那么当该数据节点的内容或是其子节点列表发生变化时，ZK服务器就会向订阅的客户端发送变更通知     
             2.对在ZK上创建的临时节点，一旦客户端与服务器之间的会话失效，那么该临时节点也就被自动清除
    利用这两大特性，就可以实现另一种集群机器存活性监控的系统
    
### 六、Master选举
        Master选举是一个在分布式系统中非常常见的应用场景。分布式最核心的特性就是能够将基友独立计算能力的系统单元部署在不同的机器上，构成一个完整的分布式系统。在分布式系统中，Master往往用来协调集群中其他系统单元，具有对分布式系统状态变更的决定权。例如，在一些读写分离的应用场景中，客户端的写请求往往是由Master来处理；在另一些场景中，Master则常常负责一些复杂的逻辑，并将处理结果同步给集群中其他系统单元。Master选举可以说是ZooKeeper最经典的应用场景。

### 七、分布式锁
        分布式锁是控制分布式系统之间同步访问共享资源的一种方式。如果不同的系统或是统一个系统的不同不急之间共享了一个或一个组资源，那么访问这些资源的时候，往往需要通过一些互斥手段来防止彼此之间的干扰，以保证一致性，在这种情况下，就不需要使用分布式锁。
        1.排他锁
          排他锁(Exclusive Locks,简称X锁),又称为写锁或独占锁，是一种基本的锁类型。如果事务T1对数据对对象O1加上排他锁，那么在整个加锁期间，只允许事务T1对O1进行读取和更新操作，其他任何事务都不能再对这个数据对象进行任何类型的操作——— 直到T1释放了排他锁。
          排他锁的核心是如何保证当期那有且仅有一个事务获得锁，并且锁被释放后，所有正在等待获取锁的事务都能被通知到。
          定义锁：在Java并发编程中，有俩种常见的方式可以用来定义锁，分别是synchronized机制和JDK5提供的ReentrantLock。然而在ZooKeeper没有类似的API直接使用，而是通过ZooKeeper上的数据节点来表示一个锁.
          获取锁：
               在需要获取排他锁时，所有的客户端都会试图通过调用create()接口，在/exclusive-lock节点下创建临时子节点/exclusive-lock/lock.如果该客户端创建锁成功了，那么就任务该客户端获取到锁了。
     2.共享锁
          共享锁(Shared Locks,简称S锁),又称为读锁，同样是一种基本的锁类型。如果事务T1对数据对象O1加上共享锁，那么当前事务只能对O1进行读取操作，其他事务也只能对这个数据对象加共享锁-直到该数据对象上的所有共享锁都被释放。
          共享锁和排他锁最根本的区别在于，加上排他锁后，数据对象只能对一个事务可见，而加上共享锁后，数据对所有事务都可见。
          定义锁：
               和排他锁一样，同样是通过ZK上的数据节点来表示一个锁，是一个类似于 /shared-lock/[hostname]-请求类型-序号 的临时顺序节点，
          获取锁:
               在需要获取共享锁时，所有客户端都会到/shared-lock 这个节点下面创建一个临时循序及诶单，如果当前是读请求，那么就创建如/shared-lock/192.168.0.1-R-0000000001的节点；如果是写请求，那就创建例如/shared-lock/192.168.0.1-W-00000001的节点
          判断读写顺序：
               根据共享锁的定义，不同的事务都可以同时对同一个数据对象进行读取操作，而更新操作必须在当前没有任何事务进行读写操作的情况进行，ZK的节点来确定分布式的读写顺序，大约分为4个步奏：
               1、创建完节点后，获取/shared-lock节点下的所有子节点，并对该节点注册子节点变更的Watcher监听
               2、确定自己的节点序号在所有子节点中的顺序
               3、对于读请求：如果没有比自己序号小的子节点，或是所有比自己序号小的子节点都是读请求，那么表明自己已经成功获取了共享锁，同时开始执行读逻辑。如果比自己序号小的子节点中有写请求，那么就需要进入等待
                  对于写请求：如果自己不是序号最小的子节点，那么就需要进入等待。
               4、接收到Watcher通知后，重复步奏1

### 八、分布式队列
    ZooKeeper实现的分布式队列。分布式队列，简答地将分为两大类，一种是最常规的先入先出队列，另外一种则是要等待队列元素聚集之后才统一安排执行的Barrier模型。


### 九、Zookeeper在大型分布式系统中的应用
     1.Hadoop      
          在Hadoop中，Zookeeper主要用于实现HA(High Availability),这部分逻辑主要集中在Hadoop Common的HA模块中，HDFS的NameNode与YARN的ResourceManager都是基于此HA模块来实现自己的HA功能的。同时，在YARN中又特别提供了ZK来存储应用的运行状态。
          YARN介绍：YARN是Hadoop为了提高计算节点Master(JT)的扩展，同时为了支持多计算模型和提供资源的细粒度调度而引入的全新一代分布式调度框架。其实可以支持MapReduce计算引擎，也支持其他的一些计算引擎，如Tez、Spark、Storm、Imlala和Open MPI等
          YARN主要由ResourceManager(RM),NodeManager(NM),ApplicationMaster(AM)和Container四部分组成。其中最核心的就是ResourceManager，它作为全局的资源管理器，负责整个系统的资源管理和分配。
          
     2.HBase
          HBase，全称Hadoop Database，是Google BigTable的开源实现，是一个机遇Hadoop文件系统设计的面向海量数据的高可靠性、高性能、面向列、可伸缩的分布式存储系统，利用HBase技术可以在廉价的PC服务器上搭建起大规模结构化的存储集群。
          与大部分分布式NoSQL数据库不同的是，HBase针对数据写入具有强一致性的特性，设置包括索引列也都实现了强一致性。ZooKeeper依然是HBase的核心组件，而且ZooKeeper在HBase中的应用场景范围也已经得到了进一步的扩展。下面将从系统云错、RootRegion管理、Region状态管理、分布式SplitLog任务管理和Replication管理来讲解ZK在HBase中的应用场景
          1.系统冗错
                当HBase启动的时候，每个RegionServer服务器都会到Zookeeper的/habse/rs节点下创建一个信息。 同时，HMaster会对这个节点注册监听。当某个RegionServer挂掉的时候，ZOOKeeper会因为在一段时间内无法接收其心跳信息(Session失效)，而删除掉该RegionServer服务器对应的rs状态节点。同时HMaster则会接收到ZK的NodeDelete通知，从而感知到某个节点断开，并立即开始冗错工作—在Hbase的实现中，HMaster会将该RegionServer所处理的数据分片(Region)重新路由到其他节点上，并记录到Meta信息中提供给客户端查询。
                HBase为什么不直接让HMaster来负责进行RegionServer的监控呢？Base之所以不使用HMaster直接通过心跳机制等来管理RegionServer状态，是因为在这种方式下，随着系统容量的不断增加，HMaster的管理负担会越来越重，另外它自身也可能会挂掉的可能，因此数据还需要持有化的必要。
           2.RootRegion管理
                对于HBase集群，数据存储的位置细信息是记录元数据分片，也就是RootRegion上的。每次客户端发起的新请求，需要知道数据的位置，就会去查询RootRegion，而RootRegion自身的位置则是记录在ZooKeeper上的(默认情况下，是记录在ZooKeeper的/hbase/root—region-server节点中).当RootRegion发生变化，比如Region的手工移动、Balance或者是RootRegion所在服务器发生故障时，就能通过ZK哎告知这变化做出一系列的容灾措施，从而保障客户端总是能拿到正确的RootRegion信息。
           3.Region状态管理
                Region是HBase中数据的物理切片，每个Region中记录了全局数据的一小部分，并且不同的Region之间的数据是相互不重复的。但对于一个分布式系统来说，Region是会经常发生变量的，这些变量的原因来自系统故障、负载均衡、配置修改，Region分裂与合并等。
           4.分布式SplitLog任务管理
                当某台RegionServer服务器挂掉时，由于总有一部分新写入的数据还没有持久化到HFile中，因此在迁移该RegionServer的服务时，一个重要的工作就是从HLog中恢复这部分还在内存中的数据，而这部分工作关键的一步就是SplitLog，即HMaster需要遍历该RegionServer服务器的HLog，并按照Region切片分成小块移动到新的地址下，并进行数据的Replay。
                由于单个RegionServer的日志量相对庞大(可能有数千个Region，上GB的日志)，而用户又往往希望系统能够快速完成日志的恢复工作。可行的方案是：将这个处理HLog的任务分配给多台RegionServer服务器来共同处理，而这就又需要一个持久化组来辅助HMaster完成任务的分配。
           5.Replication管理
                Replication是实现HBase中主备集群间的实时同步的重要模块。有了Replication，HBase就能实现主备同步，从而拥有了容灾和分流等关系数据库才拥有的功能，从而大大加强了HBase的可用性，同时也扩展了其应用场景。HBase作为分布式系统，它的Replication  是多对多的，且每个节点随时都有可能挂掉，因此在这样的场景下做Replication要比普通数据复杂。
                HBase同样借助ZK来完成Replication功能。做法是在ZK上记录一个replication节点。然后把不同的RegionServer服务器对应的HLog文件名称记录到相应的节点上，然后再重复以上过程。当服务器挂掉时，由于ZK上已经保存了断点信息，因此只要有HMaster能够根据这些断点信息来协调用来推送HLog数据的主节点服务器，就可以继续复制。
           6.ZooKeeper部署
                使用HBase内部的自带的默认的ZooKeeper，还是使用一个已有的外部的ZooKeeper集群。一般建议是使用第二种方式，因为这样就可以使得多个HBase集群复用同一套ZooKeeper集群，从而大大节省机器成本。如果一个ZooKeeper集群需要被几个HBase复用的话，那么务必为每一个HBase集群明确指明对应的ZooKeeper集群明确指明对应的ZooKeeper根节点配置(对应的配置项是zookeepr.znode.parent)，以确保各个HBase集群间互相不干扰。而对于HBase的客户端来说，只需要指明ZooKeeper的集群地址以及对应HBase的根节点配置即可，不需要任何其他的配置。当HBase集群启动的时候，会在ZooKeeper上添加相应的初始化节点，并在HMaster以及RegionServer进程中相应节点的Watcher注册。
     
     3.Kafka
          Kafka主要用于实现低延迟的发送和收集大量的事件和日志数据——>这些数据通常都是活跃的数据。所谓活跃数据，在互联网大型的Web网站应用中非常常见，通常是指网站的PV数和用户访问记录数。这些数据通常以日志的形式记录下来，然后由一个专门的系统来进行日志的收集与统计。Kafka是一个吞吐量极高的分布式消息系统，其整体设计是经典的发布与订阅模式系统。在Kafka集群中，没有 中心主节点 的概念，集群中所有的服务器都是对等的，因此，可以在不做任何配置更改的情况下实现服务器的添加与删除，同样，消息的生产者和消费者也能够做到随意重启和机器的上下线。Kafka服务器及消息生产者和消费者之间的部署关系：
    
    术语：
     尽管Kafka是一个近似符合JMS规范的消息中间实现，Kafka中的一些术语：
     .消息生产者，即Producer，是消息生产的源头，负责生产消息并发送到Kafka服务器上
     .消息消费者，即Consumer，是消息的使用放，负责消费者Kafka服务器上的消息
     .主题，即Topic，由用户定义并配置在Kafka服务端，用于建立生产者和消费者之间的订阅关系；生产者发送消息到指定Topic下，消费者从这个Topic下消费消息
     .消息分区，即Partition，一个Topic下面会分为多个分区，例如 kaka-test 这个Topic可以分为10个分区，分别由两台服务器提供，那么通常配置为让每台服务器提供5个分区；假设服务器ID分别为0和1，则所有分区为0-0,0-1,0-2,0-3,0-4和1-0，1-1，1-2，1-3，1-4.消息分区机制和分区的数量与消费者的负载均衡机制有很大的关系。
     .Broker：即Kafka的服务器，用于存储消息，在消息中间件中通常被称为Broker。
     .消费者分组：即Group，用于归组同类消费者。在Kafka中，多个消费者可以共同消费一个Topic下的消息，每个消费者消费其中的部分消息，这些消费者就组成了一个分组，拥有同一个分组名称，通常也被称为消费者集群。
     .Offest : 消息存储在Kafka的Broker上，消费者拉取消息数据的过程中需要知道消息在文件中的偏移量，这个偏移量就是所谓的Offset。
     
     Broker注册:
          Kafka是一个分布式的消息系统，这也体现在其Broker、Producer和Consumer的分布式部署，虽然Broker是分布式部署并且相互之间是独立运行的，但还是需要有一个注册系统能够将整个集群中的Broker服务器都管理起来。在Kafka的设计中，选择了使用ZooKeeper来进行所有Broker的管理；
     在ZooKeeper上会有一个专门用来进行Broker服务器列表记录的节点，简称为”Broker节点”，其节点路径为/brokers/ids.
     每个Broker服务器在启动时，都会到ZooKeeper上进行注册，即到Broker节点下创建属于自己的节点，在节点路径为/broker/ids/[0....N]
     从上面的节点路径中，我们可以看出，在Kafka中，我们使用一个全局唯一的数字来指代每个Broker服务器，可以称其为”Broker ID”,不同的Broker必须使用不同的Broker ID进行注册，例如/broker/ids/1和/broker/ids/2分别代表了俩个Broker服务器。创建完Broker节点后，每个Broker就会将自己的IP地址和端口等信息写入到该节点中去。*******Broker节点是一个临时节点，也就是说：一旦这个Broker服务器端宕机或是下线后，那么对应的Broker节点也就被删除了。因此我们可以通过ZooKeeper上Broker节点的变化情况来动态表征Broker服务器的可用性。
     
     Topic注册
          在Kafka中，会将同一个Topic的消息分成多个分区并将其分布到多个Broker上，而这些分区信息以及与Broker的对应关系也都是由ZK维护的，由专门的节点来记录，其节点路径为/brokers/topics。
          
     生产者负载均衡
          Kafka是分布式部署Broker服务器的，会对同一个Topic的消息进行分区并将其分布到不同的Broker服务器上，因此生产者需要将消息合理地发送到这些分布式的Broker上：生产者的负载均衡如何实现？对于生产者的负载均衡，Kafka支持传统的四层负载均衡，同时也支持使用ZooKeeper方式来实现负载均衡.
    ZK客户端Watcher注册流程图：
        客户端每调用一次getData()接口，就会注册上一个Watcher，那么这些Watcher实体都会随着客户端请求被发送服务器吗？
        虽然把WatchRegistration封装到了Packet对象中去，但事实上，在底层序列化的时候，没有把对应的WatchRegistration到底层的字节数组中去，那么就不会在网络中进行传输
    
    服务端处理Watcher
        最终客户端不会将Watcher对象真正传递到服务器。那么服务器究竟是如何完成客户端的Watcher注册，又是如何处理这个Watcher？
    ServerCnxn存储：
        ServerCnxn是一个ZK客户端和服务器之间的连接接口，代表了一个额客户端和服务器的连接。ServerCnxn接口的默认实现了NIOServerCnxn。实现了Watcher的process接口，因此我们可以把ServerCnxn看做一个Watcher对象。数据节点的节点路径和ServerCnxn最终会被存储在WatchManager的watchTable和watch2Paths中，WatchManager是ZooKeeper服务端Watcher的管理者，其内部管理watchTable和watch2Paths俩个存储结构，分别从俩个维度对Watcher进行存储、
            1.watchTable是从数据节点路径的粒度来托管Watcher
            2.watch2Paths是从Watcher的粒度来控制事件触发需要触发的数据节点。
        同时，WatchManager还负责Watcher事件的触发，并移除那么已经被触发的Watcher。注意，WatchManager只是一个统称，在服务端，DataTree中会托管俩个WatchManager，分别是dataWatches和childWatches，分别对应数据变更Watcher和子节点变更Watcher
        Watcher触发
            ZooKeeper会将其对应的ServerCnxn存储到WatchManager中，服务端究竟是如何触发Watcher的呢？NodeDataChanged事件的触发条件是”Watcher监听的对应的数据及诶按的数据内容发送了变更”.
            无论是dataWatches还是childWatches管理器，Watcher的触发逻辑都是一致的，步骤如下:
         1.封装WatchedEvent
              首先将通知状态(KeeperState)、事件类型(EventType)以及节点路径(path)封装成一个WatchedEvent对象
         2.查询Watcher
              根据数据节点路径从watchTable中获取对应的Watcher。如果没有找到Watcher，说明没有任何客户端在该数据节点上注册过Watcher,直接退出。而如果找到这个Watcher，会将其提取出来，同时会直接从watchTable和watch2Paths中将其删除———— Watcher在服务端是一次性的，即触发一次失效了。
         3.调用process方法来触发Watcher
              对于需要注册Watcher的请求，ZooKeeper会把当前请求对应的ServerCnxn作为一个Watcher进行存储，因此，这里调用的process方法。从process方法中，主要逻辑如下：
              1.在请求头中标记-1,表明当前是一个通知。
              2.将WatchedEvent包装成WatcherEvent，以便进行网络传输序列化
              3.向客户端发送通知
              本质上并不是客户端Watcher真正的业务逻辑，而是借助当前客户端连接的ServerCnxn对象来实现对客户端的WatchedEvent传递，真正的客户端Watcher回调与业务逻辑执行都在客户端。
   
        客户端回调Watcher
          SendThread接收事件通知：
               对于一个来自服务端的响应，客户端都是由SendThread、ReadResponse(ByteBuffer incomingBuffer)方法来统一进行处理的，如果响应头replyHdr中标识了XID为-1，表明这是一个通知类型的响应，对其的处理分为4步奏：
               1.反序列化：ZK客户端接收到请求后，首先会将字节流转为WatcherEvent对象
               2.处理chrootPath:如果客户端设置了chrootPath属性，那么需要对服务端传递过来的完整的节点路径进行chrootPath处理，生成客户端的一个相对节点路径。例如客户端设置了chrootPath为/app1,那么针对服务端传过来的响应包含的节点路径为/app1/locks,经过chrootPath处理后，就会变成一个相对路径:/locks.     
               3.还原watchedEvent:process接口的参数定义是WatchedEvent，因此这里需要将WatcherEvent对象转成WatchedEvent。
               4.回调Watcher：将WatchedEvent对象交给EventThread线程，在下一次轮询周期中进行Watcher回调
               
        EventThread处理事件通知：
             EventThread线程是ZK客户端中专门用来处理服务器通知事件的线程，SendThread接收到服务端的通知事件后，会通过调用EventThread.queueEvent方法将事件传给EventThread线程。
                    